{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom PIL import Image\nimport os\nimport csv\nfrom skimage import io\nwork_dir = \"/kaggle/input/birds-22wi/birds\"\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-03-16T02:37:44.443039Z","iopub.execute_input":"2022-03-16T02:37:44.44338Z","iopub.status.idle":"2022-03-16T02:37:46.749292Z","shell.execute_reply.started":"2022-03-16T02:37:44.443304Z","shell.execute_reply":"2022-03-16T02:37:46.748552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nprint(torch.__version__)\nprint(torch.cuda.is_available())","metadata":{"execution":{"iopub.status.busy":"2022-03-16T02:37:46.751002Z","iopub.execute_input":"2022-03-16T02:37:46.751264Z","iopub.status.idle":"2022-03-16T02:37:46.75665Z","shell.execute_reply.started":"2022-03-16T02:37:46.751229Z","shell.execute_reply":"2022-03-16T02:37:46.755995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestImageDataSet(Dataset):\n\n    def __init__(self, label_csv_file, root_dir, fileNames, transform=None):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.true_label_csv = label_csv_file\n        self.true_label_map = {}\n        self.fileNameList = fileNames\n        self.root_dir = root_dir\n        self.transform = transform\n#         self.parseLabelsToDict()\n        \n    def parseLabelsToDict(self):\n        with open(self.true_label_csv, newline='') as csvfile:\n            reader = csv.DictReader(csvfile)\n            for row in reader:\n                path = row[\"path\"]\n                classes = row[\"class\"]\n                self.true_label_map[path] = classes\n            csvfile.close()\n            \n    def __len__(self):\n        return len(self.fileNameList)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.root_dir,\n                                self.fileNameList[idx])\n        image = Image.open(img_name).convert('RGB')\n        \n        \n        item = [image, self.fileNameList[idx]]\n        if self.transform:\n            item[0] = self.transform(item[0])\n        return item[0], item[1]\n    \nclass TrainImageDataSet(Dataset):\n\n    def __init__(self, label_csv_file, root_dir, fileNames, transform=None):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.true_label_csv = label_csv_file\n        self.true_label_map = {}\n        self.fileNameList = fileNames\n        self.root_dir = root_dir\n        self.transform = transform\n        self.parseLabelsToDict()\n        \n    def parseLabelsToDict(self):\n        with open(self.true_label_csv, newline='') as csvfile:\n            reader = csv.DictReader(csvfile)\n            for row in reader:\n                path = row[\"path\"]\n                classes = row[\"class\"]\n                self.true_label_map[path] = int(classes)\n            csvfile.close()\n            \n    def __len__(self):\n        return len(self.fileNameList)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        \n        img_name = os.path.join(self.root_dir,\n                                self.fileNameList[idx])\n        image = Image.open(img_name).convert('RGB')\n        \n        imageName = self.fileNameList[idx].split(\"/\")[-1]\n        item = [image, self.true_label_map[imageName]]\n        if self.transform:\n            item[0] = self.transform(item[0])\n        return item[0], torch.tensor(item[1])","metadata":{"execution":{"iopub.status.busy":"2022-03-16T02:37:46.758086Z","iopub.execute_input":"2022-03-16T02:37:46.758637Z","iopub.status.idle":"2022-03-16T02:37:46.776403Z","shell.execute_reply.started":"2022-03-16T02:37:46.758599Z","shell.execute_reply":"2022-03-16T02:37:46.775698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_birds_data():\n    # Data augmentation transformations. Not for Testing!\n    transform_train = transforms.Compose([\n        transforms.Resize(256), # Takes images smaller than 64 and enlarges them\n        transforms.RandomCrop(256, padding=4, padding_mode='edge'), # Take 64x64 crops from 72x72 padded images\n        transforms.RandomHorizontalFlip(),    # 50% of time flip image along y-axis\n        transforms.ToTensor(),\n    ])\n\n    transform_test = transforms.Compose([\n        transforms.Resize([256,256]),\n        transforms.ToTensor(),\n    ])\n\n    trainFolderNames = os.listdir(\"/kaggle/input/birds-22wi/birds/train\")\n    trainFileNames = []\n    for name in trainFolderNames:\n        imageNames = (os.listdir(\"/kaggle/input/birds-22wi/birds/train/\" + name))\n        trainFileNames += [\"/kaggle/input/birds-22wi/birds/train/\" + name +\"/\"+ imageName for imageName in imageNames]\n    trainset = TrainImageDataSet(label_csv_file=\"/kaggle/input/birds-22wi/birds/labels.csv\", \n                               root_dir='/kaggle/input/birds-22wi/birds/train', fileNames=trainFileNames, transform=transform_train)\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n\n    testFileNames = os.listdir(\"/kaggle/input/birds-22wi/birds/test/0\")\n    testset = TestImageDataSet(label_csv_file=\"/kaggle/input/birds-22wi/birds/labels.csv\", \n                               root_dir='/kaggle/input/birds-22wi/birds/test/0', fileNames=testFileNames, transform=transform_test)\n#     testset = torchvision.datasets.ImageFolder(root='/kaggle/input/birds-22wi/birds/test/', transform=transform_test)\n    testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2, pin_memory=False)\n    return {'train': trainloader, 'test': testloader}\n\ndata = get_birds_data()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T02:37:46.779234Z","iopub.execute_input":"2022-03-16T02:37:46.780092Z","iopub.status.idle":"2022-03-16T02:38:01.201212Z","shell.execute_reply.started":"2022-03-16T02:37:46.780053Z","shell.execute_reply":"2022-03-16T02:38:01.200386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataiter = iter(data['train'])\nimages, labels = dataiter.next()\nimages = images[:8]\nprint(len(images))\nprint(images.size())\n\ndef imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(\"Labels:\" + ' '.join('%9s' % labels[j] for j in range(8)))\n\nflat = torch.flatten(images, 1)\nprint(images.size())\nprint(flat.size())","metadata":{"execution":{"iopub.status.busy":"2022-03-16T02:38:01.203631Z","iopub.execute_input":"2022-03-16T02:38:01.204217Z","iopub.status.idle":"2022-03-16T02:38:06.001647Z","shell.execute_reply.started":"2022-03-16T02:38:01.204178Z","shell.execute_reply":"2022-03-16T02:38:06.000621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#WITHOUT BIAS\nclass ConvBNNet(nn.Module):\n    def __init__(self):\n        super(ConvBNNet, self).__init__() # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n        self.conv1 = nn.Conv2d(3, 16, 3, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n\n        self.conv2 = nn.Conv2d(16, 32, 3, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(32)\n\n        self.conv3 = nn.Conv2d(32, 64, 3, padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(64)\n\n        self.conv4 = nn.Conv2d(64, 128, 3, padding=1, bias=False)\n        self.bn4 = nn.BatchNorm2d(128)\n\n        self.conv5 = nn.Conv2d(128, 256, 3, padding=1, bias=False)\n        self.bn5 = nn.BatchNorm2d(256)\n        \n        self.conv6 = nn.Conv2d(256, 512, 3, padding=1, bias=False)\n        self.bn6 = nn.BatchNorm2d(512)\n        \n        self.conv7 = nn.Conv2d(512, 1024, 3, padding=1, bias=False)\n        self.bn7 = nn.BatchNorm2d(1024)\n\n        self.fc1 = nn.Linear(1024, 555)\n\n    def forward(self, x):\n        # Input 256x256x3\n\n        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), kernel_size=2, stride=2) # 128x128x16\n        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), kernel_size=2, stride=2) # 64x64x32\n        x = F.max_pool2d(F.relu(self.bn3(self.conv3(x))), kernel_size=2, stride=2) # 32x32x64\n        x = F.max_pool2d(F.relu(self.bn4(self.conv4(x))), kernel_size=2, stride=2) # 16x16x128\n        x = F.max_pool2d(F.relu(self.bn5(self.conv5(x))), kernel_size=2, stride=2) # 8x8x256\n        x = F.max_pool2d(F.relu(self.bn6(self.conv6(x))), kernel_size=2, stride=2) # 4x4x512\n        x = F.max_pool2d(F.relu(self.bn7(self.conv7(x))), kernel_size=2, stride=2) # 2x2x1024\n\n        # Global average pooling across each channel (Input could be 2x2x256, 4x4x256, 7x3x256, output would always be 256 length vector)\n        x = F.adaptive_avg_pool2d(x, 1)                                            # 1x1x1024\n        x = torch.flatten(x, 1)                                                    # vector 1024\n        \n        x = self.fc1(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-03-16T02:38:06.004076Z","iopub.execute_input":"2022-03-16T02:38:06.004414Z","iopub.status.idle":"2022-03-16T02:38:06.044695Z","shell.execute_reply.started":"2022-03-16T02:38:06.004354Z","shell.execute_reply":"2022-03-16T02:38:06.043863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(net, dataloader, epochs=1, start_epoch=0, lr=0.01, momentum=0.9, decay=0.0005, \n          verbose=1, print_every=10, state=None, schedule={}, checkpoint_path=None):\n    net.to(device)\n    net.train()\n    losses = []\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n\n\n    for epoch in range(start_epoch, epochs):\n        sum_loss = 0.0\n\n        # Update learning rate when scheduled\n        if epoch in schedule:\n            print (\"Learning rate: %f\"% schedule[epoch])\n            for g in optimizer.param_groups:\n                g['lr'] = schedule[epoch]\n\n        for i, batch in enumerate(dataloader, 0):\n            inputs, labels = batch[0].to(device), batch[1].to(device)\n            optimizer.zero_grad()\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()  # autograd magic, computes all the partial derivatives\n            optimizer.step() # takes a step in gradient direction\n\n            losses.append(loss.item())\n            sum_loss += loss.item()\n\n            if i % print_every == print_every-1:    # print every 10 mini-batches\n                if verbose:\n                    print('[%d, %5d] loss: %.3f' % (epoch, i + 1, sum_loss / print_every))\n                sum_loss = 0.0\n            \n    return losses\n\ndef evaluate(net, dataloader):\n    net.to(device)\n    net.eval()\n    count = 1\n    df = pd.DataFrame(columns=['path', \"class\"])\n    with torch.no_grad():\n        for batch in dataloader:\n            print(\"batch:\", count)\n            count += 1\n            images = batch[0].to(device)\n            names = batch[1]\n            outputs = net(images)\n            _, predicted = torch.max(outputs.data, 1)\n            predicted = predicted.cpu()\n            for i in range(len(predicted)):\n                df = df.append({\"path\": \"test/\" + names[i], \"class\" : predicted[i].item()}, ignore_index=True)\n            \n    return df\ndef smooth(x, size):\n    return np.convolve(x, np.ones(size)/size, mode='valid')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T02:38:06.047355Z","iopub.execute_input":"2022-03-16T02:38:06.047675Z","iopub.status.idle":"2022-03-16T02:38:06.083351Z","shell.execute_reply.started":"2022-03-16T02:38:06.04764Z","shell.execute_reply":"2022-03-16T02:38:06.082492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_net = ConvBNNet()\n#Test Training\n#final_losses =  train(final_net, data['train'], epochs=1, lr=.1  , decay=.0005)\n\n#Real Training\nfinal_losses =  train(final_net, data['train'], epochs=35, lr=.1  , decay=.0005)\nfinal_losses += train(final_net, data['train'], epochs=20, lr=.01 , decay=.0005)\nfinal_losses += train(final_net, data['train'], epochs=15, lr=.001, decay=.0005)\nfinal_losses += train(final_net, data['train'], epochs=3, lr=.0001, decay=.0005)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T02:38:06.087441Z","iopub.execute_input":"2022-03-16T02:38:06.087752Z","iopub.status.idle":"2022-03-16T02:39:46.815611Z","shell.execute_reply.started":"2022-03-16T02:38:06.087715Z","shell.execute_reply":"2022-03-16T02:39:46.812329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(smooth(final_losses,50))\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T02:39:46.81745Z","iopub.status.idle":"2022-03-16T02:39:46.81807Z","shell.execute_reply.started":"2022-03-16T02:39:46.817791Z","shell.execute_reply":"2022-03-16T02:39:46.817827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"Testing  accuracy: %f\" % accuracy(net, data['test']))\nresult = evaluate(final_net, data[\"test\"])\nprint(result)  \n# total = 0\n# correct = 0\n# with torch.no_grad():\n#     for i, batch in enumerate(data[\"train\"], 0):\n#         images, labels = batch[0].to(device), batch[1].to(device)\n#         outputs = net(images)\n#         _, predicted = torch.max(outputs.data, 1)\n#         total += labels.size(0)\n#         correct += (predicted == labels).sum().item()\n#         print(i)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T02:39:46.819264Z","iopub.status.idle":"2022-03-16T02:39:46.819809Z","shell.execute_reply.started":"2022-03-16T02:39:46.819573Z","shell.execute_reply":"2022-03-16T02:39:46.819599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.to_csv(\"output.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T02:39:46.820876Z","iopub.status.idle":"2022-03-16T02:39:46.82142Z","shell.execute_reply.started":"2022-03-16T02:39:46.82119Z","shell.execute_reply":"2022-03-16T02:39:46.821213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(result[result[\"class\"] != 246])","metadata":{"execution":{"iopub.status.busy":"2022-03-16T02:39:46.827126Z","iopub.status.idle":"2022-03-16T02:39:46.827687Z","shell.execute_reply.started":"2022-03-16T02:39:46.827449Z","shell.execute_reply":"2022-03-16T02:39:46.827472Z"},"trusted":true},"execution_count":null,"outputs":[]}]}